{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **優惠券預測**\n",
    "[攻略](https://www.twblogs.net/a/5c160498bd9eee5e41842891)\n",
    "[攻略1](https://github.com/wepe/O2O-Coupon-Usage-Forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1160742, 7)\n",
      "(306313, 6)\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data/'\n",
    "dfoff = pd.read_csv(data_path + 'train_offline.csv')\n",
    "dftest = pd.read_csv(data_path + 'test_offline.csv')\n",
    "dftest = dftest[~dftest.Coupon_id.isna()]\n",
    "dftest.reset_index(drop=True, inplace=True)\n",
    "print(dfoff.shape)\n",
    "print(dftest.shape)\n",
    "# dfoff.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('15 days 00:00:00')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timedelta(15, 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. 資料轉換**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfoff['Date'] = pd.to_datetime(dfoff['Date'], format='%Y%m%d')\n",
    "dfoff['Date_received'] = pd.to_datetime(dfoff['Date_received'], format='%Y%m%d')\n",
    "dftest['Date_received'] = pd.to_datetime(dftest['Date_received'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.特徵工程**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creat target label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True, False, False])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#有優惠券且有消費之index\n",
    "dfoff.index.isin(dfoff[(~dfoff['Date_received'].isnull()) & (~dfoff['Date'].isnull())].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creat target label \n",
    "\"\"\"\n",
    "According to the definition, \n",
    "1) buy with coupon within (include) 15 days ==> 1\n",
    "2) buy with coupon but out of 15 days ==> 0\n",
    "3) buy without coupon ==> -1 (we don't care)\n",
    "\"\"\"\n",
    "def label(df):\n",
    "    df['label'] = [1 if i <= pd.Timedelta(15, 'D') else 0 for i in df['Date'] - df['Date_received']]\n",
    "    df.loc[df['Date_received'].isnull(),'label'] = -1\n",
    "    df['Writeoff_days'] = (df['Date'] - df['Date_received']).dt.days\n",
    "    df.loc[df['Date_received'].isnull(), 'Writeoff_days'] = np.nan\n",
    "\n",
    "label(dfoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-01 00:00:00 2016-04-30 00:00:00 2016-05-01 00:00:00 2016-06-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(dfoff.Date_received.min(),\\\n",
    "dfoff.Date_received.max(),\\\n",
    "dftest.Date_received.min(),\\\n",
    "dftest.Date_received.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate features - weekday acquired coupon (新增時間變數)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfoff['Date_received_weekday'] = dfoff['Date_received'].dt.weekday + 1\n",
    "dftest['Date_received_weekday'] = dftest['Date_received'].dt.weekday + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday_type :  周六和周日为1，其他为0\n",
    "dfoff['weekday_type'] = [1 if i in [6,7] else 0 for i in dfoff['Date_received_weekday']]\n",
    "dftest['weekday_type'] = [1 if i in [6,7] else 0 for i in dftest['Date_received_weekday']]\n",
    "\n",
    "# change weekday to one-hot encoding \n",
    "weekdaycols = ['weekday_' + str(i) for i in range(1,8)]\n",
    "#print(weekdaycols)\n",
    "\n",
    "tmpdf = pd.get_dummies(dfoff['Date_received_weekday'].replace('null', np.nan))\n",
    "tmpdf.columns = weekdaycols\n",
    "dfoff[weekdaycols] = tmpdf\n",
    "\n",
    "tmpdf = pd.get_dummies(dftest['Date_received_weekday'].replace('null', np.nan))\n",
    "tmpdf.columns = weekdaycols\n",
    "dftest[weekdaycols] = tmpdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **切分 train valid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 667753, #positive: 32472\n",
      "Valid size: 79216, #positive: 3832\n"
     ]
    }
   ],
   "source": [
    "df_train = dfoff[(dfoff['label'] != -1) & (dfoff['Date_received']  < '20160416') ].copy().reset_index(drop = True)\n",
    "df_valid = dfoff[(dfoff['label'] != -1) & (dfoff['Date_received'] >= '20160416')].copy().reset_index(drop = True)\n",
    "print(\"Train size: {}, #positive: {}\".format(len(df_train), df_train[\"label\"].sum()))\n",
    "print(\"Valid size: {}, #positive: {}\".format(len(df_valid), df_valid[\"label\"].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **優惠券相關的特徵**\n",
    "- 優惠券類型(直接優惠為0, 滿減為1)\n",
    "- 優惠券折率\n",
    "- 滿減優惠券的最低消費\n",
    "- 歷史出現次數\n",
    "- 歷史核銷次數\n",
    "- 歷史核銷率\n",
    "- 歷史核銷時間率\n",
    "- 領取優惠券是一周的第幾天\n",
    "- 領取優惠券是一月的第幾天\n",
    "- 歷史上用戶領取該優惠券次數\n",
    "- 歷史上用戶消費該優惠券次數\n",
    "- 歷史上用戶對該優惠券的核銷率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features - coupon discount and distance\n",
    "#優惠券類型\n",
    "def getDiscountType(row):\n",
    "    if row == 'nan':\n",
    "        return 'nan'\n",
    "    elif ':' in row:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#優惠券折扣率\n",
    "def convertRate(row):\n",
    "    \"\"\"Convert discount to rate\"\"\"\n",
    "    if row == 'nan':\n",
    "        return 1.0\n",
    "    elif ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return 1.0 - float(rows[1])/float(rows[0])\n",
    "    else:\n",
    "        return float(row)\n",
    "\n",
    "#滿減優惠的最低消費    \n",
    "def getDiscountMan(row):\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#滿減優惠的折扣費用\n",
    "def getDiscountJian(row):\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[1])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def processData(df):\n",
    "    \n",
    "    # convert discunt_rate\n",
    "    df['discount_type'] = df['Discount_rate'].astype('str').apply(getDiscountType)\n",
    "    df['discount_rate'] = df['Discount_rate'].astype('str').apply(convertRate)\n",
    "    df['discount_man'] = df['Discount_rate'].astype('str').apply(getDiscountMan)\n",
    "    df['discount_jian'] = df['Discount_rate'].astype('str').apply(getDiscountJian)\n",
    "    \n",
    "    # convert distance,將na改為距離很遠\n",
    "    df.loc[df.Distance.isna(), \"Distance\"] = 99\n",
    "    return df\n",
    "\n",
    "df_train = processData(df_train)\n",
    "df_valid = processData(df_valid)\n",
    "dfoff = processData(dfoff)\n",
    "dftest = processData(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 優惠券歷史出現次數/核銷次數 (核銷率) 注意要用df_train ,dfoff\n",
    "def Coupon(df,df_m):\n",
    "    d = df.merge(df_m.groupby(['Coupon_id'])[['Coupon_id']].count().rename(columns = {'Coupon_id':'Coupon_count'}).reset_index(),\\\n",
    "                 on = 'Coupon_id', how = 'left').merge(df_m[df_m['label'] == 1].groupby(['Coupon_id'])[['Coupon_id']].count()\\\n",
    "                .rename(columns = {'Coupon_id':'Coupon_buy'}).reset_index(), on = 'Coupon_id', how = 'left')\n",
    "    return d\n",
    "\n",
    "df_train = Coupon(df_train, df_train)\n",
    "df_valid = Coupon(df_valid, df_train)\n",
    "dftest = Coupon(dftest, dfoff)\n",
    "\n",
    "#核銷率\n",
    "def write_off(df):\n",
    "    df['Coupon_writeoff'] = df['Coupon_buy']/df['Coupon_count']\n",
    "\n",
    "write_off(df_train)\n",
    "write_off(df_valid)\n",
    "write_off(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 歷史核銷時間率, 每個優惠券被領取後，平均核銷天數\n",
    "# write_off_days\n",
    "def write_off_days(df, df_m):\n",
    "    d = df.merge(df_m.groupby(['Coupon_id'])[['Writeoff_days']].mean()\\\n",
    "               .rename(columns = {'Writeoff_days':'Mean_Writeoff_days'}).reset_index(),on = 'Coupon_id', how = 'left')\n",
    "    return d\n",
    "\n",
    "df_train = write_off_days(df_train, df_train)\n",
    "df_valid = write_off_days(df_valid, df_train)\n",
    "dftest = write_off_days(dftest, dfoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 領取優惠券是該月第幾天\n",
    "def day(df):\n",
    "    df['day'] = df['Date_received'].dt.day\n",
    "day(df_train)\n",
    "day(df_valid)\n",
    "day(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Distance',\n",
       "       'Date_received', 'Date', 'label', 'Writeoff_days',\n",
       "       'Date_received_weekday', 'weekday_type', 'weekday_1', 'weekday_2',\n",
       "       'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7',\n",
       "       'discount_type', 'discount_rate', 'discount_man', 'discount_jian',\n",
       "       'Coupon_count', 'Coupon_buy', 'Coupon_writeoff', 'Mean_Writeoff_days',\n",
       "       'day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **用戶特徵**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 用戶領取優惠券次數\n",
    "- 用戶獲得優惠券但沒有消費的次數\n",
    "- 用戶獲得優惠券並核銷次數\n",
    "- 用戶領取優惠券後進行核銷率\n",
    "- 用戶個別優惠券核銷率 # 個別優惠券領取/核銷數 核銷率 (- 用戶核銷過的不同優惠券數量，及其占所有不同優惠券的比重)\n",
    "- 用戶核銷滿100, 150, 200, 300 減的優惠券佔所有核銷優惠券的比重 \n",
    "- 用戶核銷過優惠券的不同商家數量，及其占所有不同商家的比重\n",
    "- 歷史核銷時間率, 每個用戶領取優惠券後，平均核銷天數\n",
    "\n",
    "\n",
    "#- 用戶核銷優惠券的平均/最低/最高消費折率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用戶領取優惠券次數/核銷次數/未使用次數\n",
    "def User(df, df_m):\n",
    "    d = df.merge(df_m[df_m['label'] != -1].groupby(['User_id'])[['User_id']].count().rename(columns = {'User_id':'User_count'}).reset_index(),\\\n",
    "                 on = 'User_id', how = 'left').merge(df_m[df_m['label'] == 1].groupby(['User_id'])[['User_id']].count()\\\n",
    "                 .rename(columns = {'User_id':'User_buy'}).reset_index(), on = 'User_id', how = 'left')\\\n",
    "                 .merge(df_m[df_m['label'] == 0].groupby(['User_id'])[['User_id']].count()\\\n",
    "                 .rename(columns = {'User_id':'User_unbuy'}).reset_index(), on = 'User_id', how = 'left')\n",
    "    return d\n",
    "\n",
    "df_train = User(df_train, df_train)\n",
    "df_valid = User(df_valid, df_train)\n",
    "dftest = User(dftest, dfoff)\n",
    "\n",
    "#核銷率\n",
    "def write_off(df):\n",
    "    df['User_writeoff'] = df['User_buy']/df['User_count']\n",
    "\n",
    "write_off(df_train)\n",
    "write_off(df_valid)\n",
    "write_off(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用戶個別優惠券領取次數/核銷數 核銷率\n",
    "def User_Coupon(df, df_m):\n",
    "    d = df.merge(df_m[df_m['label'] != -1].groupby(['User_id', 'Coupon_id'])[['Coupon_id']].count()\\\n",
    "                 .rename(columns = {'Coupon_id':'User_coupon_count'}).reset_index(),on = ['User_id','Coupon_id'], how = 'left')\\\n",
    "                 .merge(df_m[df_m['label'] == 1].groupby(['User_id', 'Coupon_id'])[['Coupon_id']].count()\\\n",
    "                 .rename(columns = {'Coupon_id':'User_Coupon_buy'}).reset_index(), on = ['User_id','Coupon_id'], how = 'left')\n",
    "    return d\n",
    "\n",
    "df_train = User_Coupon(df_train, df_train)\n",
    "df_valid = User_Coupon(df_valid, df_train)\n",
    "dftest = User_Coupon(dftest, dfoff)\n",
    "\n",
    "#用戶個別優惠券領取核銷率\n",
    "def write_off(df):\n",
    "    df['User_coupon_writeoff'] = df['User_Coupon_buy']/df['User_coupon_count']    \n",
    "    \n",
    "write_off(df_train)\n",
    "write_off(df_valid)\n",
    "write_off(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 用戶核銷滿 100, 150, 200, 300 減的優惠券佔所有核銷優惠券的比重 \n",
    "# - 用戶核銷滿 5,20, 30, 50 減的優惠券佔所有核銷優惠券的比重 \n",
    "def man(df,df_m):\n",
    "    d = df.merge(df_m[(df_train['label'] == 1) & df_m['discount_man'].isin(['100', '150', '200', '300'])]\\\n",
    "          .groupby(['User_id'])[['User_id']].count().rename(columns = {'User_id':'Man_100_buy'}).reset_index(),\\\n",
    "          on = 'User_id', how = 'left')\\\n",
    "          .merge(df_m[(df_train['label'] == 1) & df_m['discount_man'].isin(['5', '20', '30', '50'])]\\\n",
    "          .groupby(['User_id'])[['User_id']].count().rename(columns = {'User_id':'Man_5_buy'}).reset_index(),\\\n",
    "          on = 'User_id', how = 'left')\n",
    "    return d\n",
    "    \n",
    "df_train = man(df_train, df_train)\n",
    "df_valid = man(df_valid, df_train)\n",
    "dftest = man(dftest, dfoff)\n",
    "\n",
    "def write_off(df):\n",
    "    df['User_Man_100_write_off'] = df['Man_100_buy']/df['User_buy']    \n",
    "    df['User_Man_5_write_off'] = df['Man_5_buy']/df['User_buy']\n",
    "    \n",
    "write_off(df_train)\n",
    "write_off(df_valid)\n",
    "write_off(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 用戶個別核銷過的優惠券佔用戶總核銷優惠券比重\n",
    "def write_off(df):\n",
    "    df['User_coupon_writeoff_proportion'] = df['User_Coupon_buy']/df['User_buy']\n",
    "\n",
    "write_off(df_train)\n",
    "write_off(df_valid)\n",
    "write_off(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 用戶核銷過優惠券的不同商家數量，及其占所有不同商家的比重\n",
    "def write_off(df,df_m):\n",
    "    d = df.merge(df_m[df_m['label'] == 1].groupby(['User_id','Merchant_id'])[['Merchant_id']].count()\\\n",
    "                .rename(columns = {'Merchant_id':'User_Merchant_buy'}).reset_index(), on = ['User_id', 'Merchant_id'], how = 'left')\n",
    "    return d\n",
    "\n",
    "df_train = write_off(df_train,df_train)\n",
    "df_valid = write_off(df_valid,df_train)\n",
    "dftest = write_off(dftest,dfoff)\n",
    "\n",
    "def write_off(df):\n",
    "    df['User_Merchant_writeoff_propotion'] = df['User_Merchant_buy']/df['User_buy']    \n",
    "    \n",
    "write_off(df_train)\n",
    "write_off(df_valid)\n",
    "write_off(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 歷史核銷時間率, 每個用戶領取優惠券後，平均核銷天數\n",
    "def write_off_days(df, df_m):\n",
    "    d = df.merge(df_m[df_m['Writeoff_days'] >= 0].groupby(['User_id'])[['Writeoff_days']].mean()\\\n",
    "                 .rename(columns = {'Writeoff_days':'User_Mean_Writeoff_days'}).reset_index()\n",
    "                 ,on = 'User_id', how = 'left')\n",
    "    return d\n",
    "\n",
    "df_train = write_off_days(df_train,df_train)\n",
    "df_valid = write_off_days(df_valid, df_train)\n",
    "dftest = write_off_days(dftest, dfoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **商家特徵**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 商家優惠券被領取次數 (Merchant_count)\n",
    "- 商家優惠券被領取後不核銷次數 (Merchant_unbuy)\n",
    "- 商家優惠券被領取後核銷次數(Merchant_buy)\n",
    "- 商家優惠券被領取後核銷率 (Merchant_writeoff)\n",
    "- 核銷商家優惠券的不同用戶數量，及其占領取不同的用戶比重 (商家優惠券核銷用戶數 Merchant_User_buy 及領取用戶數 Merchant_User_count)\n",
    "- 商家優惠券平均每個用戶核銷多少張 (Merchant_buy/Merchant_User_buy)\n",
    "- 商家被核銷過的不同優惠券數量 (Merhcant_Coupon_buy)\n",
    "- 商家被核銷過的不同優惠券數量佔所有領取過的不同優惠券數量的比重 (Merchant_Coupon_writeoff : M_C_Buy/M_C_Count)\n",
    "- 歷史核銷時間率, 每個商家的優惠券被領取後，平均核銷天數\n",
    "\n",
    "#- 商家優惠券核銷的平均/最小/最大消費折率 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#商家優惠券被領取次數 / 不核銷次數 / 核銷次數\n",
    "def Merchant(df, df_m):\n",
    "    d = df.merge(df_m[df_m['label'] != -1].groupby(['Merchant_id'])[['Merchant_id']].count()\\\n",
    "                 .rename(columns = {'Merchant_id':'Merchant_count'}).reset_index(),on = 'Merchant_id', how = 'left')\\\n",
    "                 .merge(df_m[df_m['label'] == 1].groupby(['Merchant_id'])[['Merchant_id']].count()\\\n",
    "                 .rename(columns = {'Merchant_id':'Merchant_buy'}).reset_index(), on = 'Merchant_id', how = 'left')\\\n",
    "                 .merge(df_m[df_m['label'] == 0].groupby(['Merchant_id'])[['Merchant_id']].count()\\\n",
    "                 .rename(columns = {'Merchant_id':'Merchant_unbuy'}).reset_index(), on = 'Merchant_id', how = 'left')\n",
    "    return d\n",
    "\n",
    "df_train = Merchant(df_train, df_train)\n",
    "df_valid = Merchant(df_valid, df_train)\n",
    "dftest = Merchant(dftest, dfoff)\n",
    "\n",
    "#核銷率\n",
    "def write_off(df):\n",
    "    df['Merchant_writeoff'] = df['Merchant_buy']/df['Merchant_count']\n",
    "\n",
    "write_off(df_train)\n",
    "write_off(df_valid)\n",
    "write_off(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 商家優惠券核銷用戶數 Merchant_User_buy 及領取用戶數 Merchant_User_count\n",
    "def Merchant_user(df, df_m):\n",
    "    d = df.merge(df_m[df_m['label'] != -1].groupby(['Merchant_id'])[['User_id']].nunique()\\\n",
    "                 .rename(columns = {'User_id':'Merchant_User_count'}).reset_index(),on = 'Merchant_id', how = 'left')\\\n",
    "                 .merge(df_m[df_m['label'] == 1].groupby(['Merchant_id'])[['User_id']].nunique()\\\n",
    "                 .rename(columns = {'User_id':'Merchant_User_buy'}).reset_index(), on = 'Merchant_id', how = 'left')\n",
    "    return d\n",
    "\n",
    "df_train = Merchant_user(df_train, df_train)\n",
    "df_valid = Merchant_user(df_valid, df_train)\n",
    "dftest = Merchant_user(dftest, dfoff)\n",
    "\n",
    "#核銷率\n",
    "def write_off(df):\n",
    "    df['Merchant_User_writeoff'] = df['Merchant_User_buy']/df['Merchant_User_count']\n",
    "\n",
    "write_off(df_train)\n",
    "write_off(df_valid)\n",
    "write_off(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 商家優惠券平均每個用戶核銷多少張 (Merchant_buy/Merchant_User_buy)\n",
    "def Merchant_avguser(df):\n",
    "    df['Merchant_Avguser_buy'] = df['Merchant_buy'] / df['Merchant_User_buy']\n",
    "\n",
    "Merchant_avguser(df_train)\n",
    "Merchant_avguser(df_valid)\n",
    "Merchant_avguser(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 商家被核銷過的不同優惠券數量 (Merhcant_Coupon_buy)\n",
    "# - 商家被核銷過的不同優惠券數量佔所有領取過的不同優惠券數量的比重 (Merchant_Coupon_writeoff : M_C_Buy/M_C_Count)\n",
    "def Merchant_coupon(df, df_m):\n",
    "    d = df.merge(df_m[df_m['label'] != -1].groupby(['Merchant_id', 'Coupon_id'])[['Coupon_id']].count().rename(columns = \\\n",
    "          {'Coupon_id':'Merhcant_Coupon_count'}).reset_index(), on = ['Merchant_id', 'Coupon_id'], how = 'left')\\\n",
    "          .merge(df_train[df_train['label'] == 1].groupby(['Merchant_id', 'Coupon_id'])[['Coupon_id']].count().rename(columns =\\\n",
    "          {'Coupon_id':'Merhcant_Coupon_buy'}).reset_index(), on = ['Merchant_id', 'Coupon_id'], how = 'left')\n",
    "    return d\n",
    "\n",
    "df_train = Merchant_coupon(df_train, df_train)\n",
    "df_valid = Merchant_coupon(df_valid, df_train)\n",
    "dftest = Merchant_coupon(dftest, dfoff)\n",
    "\n",
    "#核銷率\n",
    "def write_off(df):\n",
    "    df['Merchant_Coupon_writeoff'] = df['Merhcant_Coupon_buy']/df['Merhcant_Coupon_count']\n",
    "\n",
    "write_off(df_train)\n",
    "write_off(df_valid)\n",
    "write_off(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 歷史核銷時間率, 每個商家的優惠券被領取後，平均核銷天數\n",
    "def write_off_days(df, df_m):\n",
    "    d = df.merge(df_m[df_m['Writeoff_days'] >= 0].groupby(['Merchant_id'])[['Writeoff_days']].mean()\\\n",
    "                 .rename(columns = {'Writeoff_days':'Merchant_Mean_Writeoff_days'}).reset_index()\n",
    "                 ,on = 'Merchant_id', how = 'left')\n",
    "    return d\n",
    "\n",
    "df_train = write_off_days(df_train,df_train)\n",
    "df_valid = write_off_days(df_valid, df_train)\n",
    "dftest = write_off_days(dftest, dfoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **用戶商家交互特徵**\n",
    "- 用戶領取商家的優惠券次數\n",
    "- 用戶領取商家的優惠券後不核銷次數\n",
    "- 用戶領取商家的優惠券後核銷次數\n",
    "- 用戶領取商家的優惠券後核銷率\n",
    "- 用戶對每個商家的不核銷次數佔用戶總的不核銷次數的比重\n",
    "- 用戶對每個商家的優惠券核銷次數佔用戶總的核銷次數的比重\n",
    "- 用戶對每個商家的不核銷次數佔商家總的不核銷次數的比重\n",
    "- 用戶對每個商家的優惠券核銷次數佔商家總的核銷次數的比重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1輸出處理好之資料**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv('df_train.csv',index = False)\n",
    "# df_valid.to_csv('df_valid.csv',index = False)\n",
    "# dfoff.to_csv('dfoff.csv',index = False)\n",
    "# dftest.to_csv('dftest.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. 建模**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1 輸入處理好之資料**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfoff = pd.read_csv('dfoff.csv')\n",
    "dftest = pd.read_csv('dftest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 ['discount_rate', 'discount_type', 'discount_man', 'discount_jian', 'Distance', 'Date_received_weekday', 'weekday_type', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    }
   ],
   "source": [
    "original_feature = ['discount_rate',\n",
    "                    'discount_type',\n",
    "                    'discount_man', \n",
    "                    'discount_jian',\n",
    "                    'Distance', \n",
    "                    'Date_received_weekday', \n",
    "                    'weekday_type'] + weekdaycols\n",
    "print(len(original_feature),original_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Merchant_id', 'Coupon_id','Date_received_weekday', 'Distance', 'weekday_type', 'weekday_1', 'weekday_2', 'weekday_3', \n",
    "            'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7', 'discount_type', 'discount_rate', 'discount_man', 'discount_jian',\n",
    "            'Coupon_count', 'Coupon_buy', 'Coupon_writeoff', 'Mean_Writeoff_days', 'day', 'User_count', 'User_buy', 'User_unbuy', \n",
    "            'User_writeoff', 'User_coupon_count', 'User_Coupon_buy', 'User_coupon_writeoff', 'Man_100_buy', 'Man_5_buy', \n",
    "            'User_Man_100_write_off', 'User_Man_5_write_off', 'User_coupon_writeoff_proportion', 'User_Merchant_buy', \n",
    "            'User_Merchant_writeoff_propotion', 'User_Mean_Writeoff_days', 'Merchant_writeoff', 'Merchant_count', \n",
    "            'Merchant_buy', 'Merchant_unbuy', 'Merchant_User_count', 'Merchant_User_buy', 'Merchant_User_writeoff', \n",
    "            'Merchant_Avguser_buy', 'Merhcant_Coupon_count', 'Merhcant_Coupon_buy','Merchant_Coupon_writeoff', \n",
    "            'Merchant_Mean_Writeoff_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_find = ['Coupon_count', 'Coupon_buy', 'Coupon_writeoff', 'Mean_Writeoff_days', 'day', 'User_count', 'User_buy', \n",
    " 'User_unbuy', 'User_writeoff', 'User_coupon_count', 'User_Coupon_buy', 'User_coupon_writeoff', 'Man_100_buy', 'Man_5_buy', \n",
    " 'User_Man_100_write_off', 'User_Man_5_write_off', 'User_coupon_writeoff_proportion', 'User_Merchant_buy', \n",
    " 'User_Merchant_writeoff_propotion', 'User_Mean_Writeoff_days', 'Merchant_writeoff', 'Merchant_count', \n",
    " 'Merchant_buy', 'Merchant_unbuy', 'Merchant_User_count', 'Merchant_User_buy', 'Merchant_User_writeoff', \n",
    " 'Merchant_Avguser_buy', 'Merhcant_Coupon_count', 'Merhcant_Coupon_buy','Merchant_Coupon_writeoff', \n",
    " 'Merchant_Mean_Writeoff_days']\n",
    "\n",
    "na_col = []\n",
    "for i,j in  zip(na_find,df_train[na_find].isnull().any()):\n",
    "    if j == True:\n",
    "        na_col.append(i)\n",
    "        \n",
    "na_0 = list(set(na_col)-set(['Mean_Writeoff_days', 'User_Mean_Writeoff_days', 'Merchant_Mean_Writeoff_days'])) \n",
    "na_1 = ['Mean_Writeoff_days', 'User_Mean_Writeoff_days', 'Merchant_Mean_Writeoff_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna(df):\n",
    "    df[na_0] = df[na_0].fillna(0)\n",
    "    df[na_1] = df[na_1].fillna(-1)\n",
    "\n",
    "fillna(df_train)\n",
    "fillna(df_valid)\n",
    "fillna(dftest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Merchant_id', 'Coupon_id', 'Date_received_weekday', 'Distance', 'weekday_type', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7', 'discount_type', 'discount_rate', 'discount_man', 'discount_jian', 'Coupon_count', 'Coupon_buy', 'Coupon_writeoff', 'Mean_Writeoff_days', 'day', 'User_count', 'User_buy', 'User_unbuy', 'User_writeoff', 'User_coupon_count', 'User_Coupon_buy', 'User_coupon_writeoff', 'Man_100_buy', 'Man_5_buy', 'User_Man_100_write_off', 'User_Man_5_write_off', 'User_coupon_writeoff_proportion', 'User_Merchant_buy', 'User_Merchant_writeoff_propotion', 'User_Mean_Writeoff_days', 'Merchant_writeoff', 'Merchant_count', 'Merchant_buy', 'Merchant_unbuy', 'Merchant_User_count', 'Merchant_User_buy', 'Merchant_User_writeoff', 'Merchant_Avguser_buy', 'Merhcant_Coupon_count', 'Merhcant_Coupon_buy', 'Merchant_Coupon_writeoff', 'Merchant_Mean_Writeoff_days']\n"
     ]
    }
   ],
   "source": [
    "predictors = features\n",
    "print(predictors)\n",
    "\n",
    "def check_model(data, predictors):\n",
    "    \n",
    "    classifier = lambda: SGDClassifier(\n",
    "        loss='log', \n",
    "        penalty='elasticnet', \n",
    "        fit_intercept=True, \n",
    "        max_iter=100, \n",
    "        shuffle=True, \n",
    "        n_jobs=1,\n",
    "        class_weight=None)\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        ('ss', StandardScaler()),\n",
    "        ('en', classifier())\n",
    "    ])\n",
    "\n",
    "    parameters = {\n",
    "        'en__alpha': [ 0.001, 0.01, 0.1],\n",
    "        'en__l1_ratio': [ 0.001, 0.01, 0.1]\n",
    "    }\n",
    "\n",
    "    folder = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        model, \n",
    "        parameters, \n",
    "        cv=folder, \n",
    "        n_jobs=-1, \n",
    "        verbose=1)\n",
    "    grid_search = grid_search.fit(data[predictors], \n",
    "                                  data['label'])\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "model = check_model(df_train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "#預測 0416 ~ 0430, validation\n",
    "df_valid_pred = model.predict_proba(df_valid[predictors].fillna(0))\n",
    "df_valid_1 = df_valid.copy()\n",
    "df_valid_1['pred_prob'] = df_valid_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.807, Accuracy: 0.950\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "auc_score = roc_auc_score(y_true = df_valid.label, y_score = df_valid_pred[:,1])\n",
    "acc = accuracy_score(y_true = df_valid.label, y_pred = df_valid_pred.argmax(axis=1))\n",
    "print(\"Validation AUC: {:.3f}, Accuracy: {:.3f}\".format(auc_score, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 51)\n",
      "(306313, 49)\n"
     ]
    }
   ],
   "source": [
    "# 預測 test set\n",
    "dftest_1 = dftest.copy()\n",
    "print(dftest_1.shape)\n",
    "dftest_1 = dftest_1[~dftest_1.Coupon_id.isna()].reset_index(drop=True) #篩出要預測的(有領優惠券)\n",
    "testset = dftest_1[predictors].copy() #先選部分變數\n",
    "\n",
    "df_test_pred = model.predict_proba(testset[predictors].fillna(0)) #預測0501~0630\n",
    "test1 = testset.copy()\n",
    "test1['pred_prob'] = df_test_pred[:, 1]\n",
    "print(test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 4)\n"
     ]
    }
   ],
   "source": [
    "# 轉成 df 檔\n",
    "output = pd.concat((dftest_1[['User_id', 'Coupon_id', 'Date_received']], test1['pred_prob']), axis=1)\n",
    "print(output.shape)\n",
    "output['Date_received'] = output['Date_received'].dt.strftime('%Y%m%d')\n",
    "output.loc[:, 'User_id'] = output['User_id'].apply(lambda x:str(int(x)))\n",
    "output.loc[:, 'Coupon_id'] = output['Coupon_id'].apply(lambda x:str(int(x)))\n",
    "output.loc[:, 'Date_received'] = output['Date_received'].apply(lambda x:str(int(x)))\n",
    "output['uid'] = output[['User_id', 'Coupon_id', 'Date_received']].apply(lambda x: '_'.join(x.values), axis=1)\n",
    "output.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000020_2705_20160519</td>\n",
       "      <td>1.989950e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000020_8192_20160513</td>\n",
       "      <td>2.105922e-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000065_1455_20160527</td>\n",
       "      <td>7.148922e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000085_8067_20160513</td>\n",
       "      <td>2.162863e-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000086_2418_20160613</td>\n",
       "      <td>8.892678e-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     uid         label\n",
       "0  1000020_2705_20160519  1.989950e-29\n",
       "1  1000020_8192_20160513  2.105922e-30\n",
       "2  1000065_1455_20160527  7.148922e-14\n",
       "3  1000085_8067_20160513  2.162863e-30\n",
       "4  1000086_2418_20160613  8.892678e-30"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN NAME: uid, label\n",
    "out = output.groupby(\"uid\", as_index=False).mean()\n",
    "out = out[[\"uid\", \"pred_prob\"]]\n",
    "out.columns = [\"uid\", \"label\"]\n",
    "out.to_csv(\"Feature_1.csv\", header=[\"uid\", \"label\"], index=False) # submission format\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import  XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_train['label']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_train[predictors], Y, test_size = 0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (467427, 46)\n",
      "Y_train : (467427,)\n",
      "X_test : (200326, 46)\n",
      "Y_test : (200326,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train :', X_train.shape )\n",
    "print('Y_train :', Y_train.shape )\n",
    "print('X_test :', X_test.shape )\n",
    "print('Y_test :', Y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.563962798718897"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].values.tolist().count(0)/df_train['label'].values.tolist().count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(scale_pos_weight = 19.5640, min_child_weight = 1\n",
    "                    ,max_depth = 3,learning_rate = 0.1, random_state = 1000,\n",
    "                    objective='binary:logistic', n_estimators= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=1000,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=19.564, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict_prob = xgb.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = pd.Series(Y_predict_prob).copy()\n",
    "Y_predict[Y_predict<0.5] = 0\n",
    "Y_predict[Y_predict>=0.5] = 1\n",
    "print('Accuracy is ', accuracy_score(Y_test, Y_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score = 0.8502\n",
      "Recall score = 0.9989\n",
      "F1 score = 0.9186\n",
      "Roc AUC:  0.9994959792539468\n",
      "Accuracy is  99.13690684184779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "scorePrecision = precision_score(Y_test.values, Y_predict.values)\n",
    "scoreRecall = recall_score(Y_test.values, Y_predict.values)\n",
    "scoreF1 = f1_score(Y_test.values, Y_predict.values)\n",
    "print(f\"Precision score = {scorePrecision:.4f}\")\n",
    "print(f\"Recall score = {scoreRecall:.4f}\")\n",
    "print(f\"F1 score = {scoreF1:.4f}\")\n",
    "print(\"Roc AUC: \", roc_auc_score(Y_test, Y_predict_prob,\n",
    "              average='macro'))\n",
    "print('Accuracy is ', accuracy_score(Y_test, Y_predict)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  94.91138153908302\n"
     ]
    }
   ],
   "source": [
    "# predict validation\n",
    "Y_valid_prob = xgb.predict_proba(df_valid[predictors].fillna(0))[:,1]\n",
    "Y_valid = pd.Series(Y_valid_prob).copy()\n",
    "Y_valid[Y_valid<0.5] = 0\n",
    "Y_valid[Y_valid>=0.5] = 1\n",
    "print('Accuracy is ', accuracy_score(df_valid.label, Y_valid)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score = 0.3873\n",
      "Recall score = 0.0892\n",
      "F1 score = 0.1451\n",
      "Roc AUC:  0.5868802046673433\n",
      "Accuracy is  94.91138153908302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "scorePrecision = precision_score(df_valid.label.values, Y_valid.values)\n",
    "scoreRecall = recall_score(df_valid.label.values, Y_valid.values)\n",
    "scoreF1 = f1_score(df_valid.label.values, Y_valid.values)\n",
    "print(f\"Precision score = {scorePrecision:.4f}\")\n",
    "print(f\"Recall score = {scoreRecall:.4f}\")\n",
    "print(f\"F1 score = {scoreF1:.4f}\")\n",
    "print(\"Roc AUC: \", roc_auc_score(df_valid.label, Y_valid_prob,\n",
    "              average='macro'))\n",
    "print('Accuracy is ', accuracy_score(df_valid.label, Y_valid)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test_prob = xgb.predict_proba(dftest[predictors].fillna(0))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 4)\n"
     ]
    }
   ],
   "source": [
    "# 轉成 df 檔\n",
    "output = dftest_1[['User_id', 'Coupon_id', 'Date_received']].copy()\n",
    "output['pred_prob'] = Y_pred_test_prob\n",
    "print(output.shape)\n",
    "output['Date_received'] = output['Date_received'].dt.strftime('%Y%m%d')\n",
    "output.loc[:, 'User_id'] = output['User_id'].apply(lambda x:str(int(x)))\n",
    "output.loc[:, 'Coupon_id'] = output['Coupon_id'].apply(lambda x:str(int(x)))\n",
    "output.loc[:, 'Date_received'] = output['Date_received'].apply(lambda x:str(int(x)))\n",
    "output['uid'] = output[['User_id', 'Coupon_id', 'Date_received']].apply(lambda x: '_'.join(x.values), axis=1)\n",
    "output.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000020_2705_20160519</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000020_8192_20160513</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000065_1455_20160527</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000085_8067_20160513</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000086_2418_20160613</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     uid     label\n",
       "0  1000020_2705_20160519  0.000022\n",
       "1  1000020_8192_20160513  0.000022\n",
       "2  1000065_1455_20160527  0.000095\n",
       "3  1000085_8067_20160513  0.000022\n",
       "4  1000086_2418_20160613  0.000022"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN NAME: uid, label\n",
    "out = output.groupby(\"uid\", as_index=False).sum()\n",
    "out = out[[\"uid\", \"pred_prob\"]]\n",
    "out.columns = [\"uid\", \"label\"]\n",
    "out.to_csv(\"XGB_Example.csv\", header=[\"uid\", \"label\"], index=False) # submission format\n",
    "out.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
